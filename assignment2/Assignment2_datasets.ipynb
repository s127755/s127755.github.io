{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>In this file the datasets (json files) for assignment 2 are generated.</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Inports\n",
    "import csv\n",
    "import operator\n",
    "import numpy as np\n",
    "import json\n",
    "import random\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assignment 2A: One scatter plot and two datasets\n",
    "\n",
    "We will be visualizing SF crime data (the same dataset we've used in all the exerciese). This scatter plot visualization should pull data from an associated CSV/JSON file (it's easiest to use Python to generate a nicely formatted file that contains only the data you need for the visualization). You should use appropriate dynamic scales (see chapter 7 of IDV). Additional requirements for the visualizations are listed below\n",
    "\n",
    "Each point should correspond to a district\n",
    "Points should be labeled\n",
    "The radius of a point should be proportional to total number of crimes in that district\n",
    "The xx-axis should correspond to total number of PROSTITUTION incidents\n",
    "The yy-axis should correspond to total number of VEHICLE THEFT incidents\n",
    "Click on something (your choice) to toggle between data from 2003 and 2015 - there must be a smooth transition.\n",
    "Axes should not change but fit data from both years (e.g. when setting up the dynamic scales, the max values should be set by taking both datasets into arrount).\n",
    "Explain in your own words why you think I want the axes to be the same for both years? (Even though you know how to make axes adapt to the data values.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CENTRAL': {'P': 70, 'Total': 13622, 'District': 'CENTRAL', 'V': 1193}, 'NORTHERN': {'P': 581, 'Total': 18975, 'District': 'NORTHERN', 'V': 1879}, 'SOUTHERN': {'P': 18, 'Total': 25692, 'District': 'SOUTHERN', 'V': 1426}, 'PARK': {'P': 2, 'Total': 8219, 'District': 'PARK', 'V': 1207}, 'MISSION': {'P': 713, 'Total': 21163, 'District': 'MISSION', 'V': 2063}, 'TENDERLOIN': {'P': 527, 'Total': 12737, 'District': 'TENDERLOIN', 'V': 371}, 'RICHMOND': {'P': 15, 'Total': 7692, 'District': 'RICHMOND', 'V': 1081}, 'TARAVAL': {'P': 10, 'Total': 11329, 'District': 'TARAVAL', 'V': 1665}, 'INGLESIDE': {'P': 5, 'Total': 14008, 'District': 'INGLESIDE', 'V': 2319}, 'BAYVIEW': {'P': 11, 'Total': 15739, 'District': 'BAYVIEW', 'V': 2121}}\n",
      "{'CENTRAL': {'P': 44, 'Total': 18565, 'District': 'CENTRAL', 'V': 552}, 'NORTHERN': {'P': 42, 'Total': 20092, 'District': 'NORTHERN', 'V': 945}, 'SOUTHERN': {'P': 96, 'Total': 30095, 'District': 'SOUTHERN', 'V': 795}, 'PARK': {'P': 1, 'Total': 9341, 'District': 'PARK', 'V': 640}, 'MISSION': {'P': 66, 'Total': 18542, 'District': 'MISSION', 'V': 1198}, 'TENDERLOIN': {'P': 23, 'Total': 10735, 'District': 'TENDERLOIN', 'V': 113}, 'RICHMOND': {'P': 9, 'Total': 9082, 'District': 'RICHMOND', 'V': 561}, 'TARAVAL': {'P': 81, 'Total': 11966, 'District': 'TARAVAL', 'V': 789}, 'INGLESIDE': {'P': 5, 'Total': 13414, 'District': 'INGLESIDE', 'V': 1368}, 'BAYVIEW': {'P': 7, 'Total': 14711, 'District': 'BAYVIEW', 'V': 985}}\n"
     ]
    }
   ],
   "source": [
    "#Creating dataset with districts\n",
    "\n",
    "listOf2003Districts = {}\n",
    "listOf2015Districts = {}\n",
    "\n",
    "with open(\"SFPD.csv\", \"r\") as csvfile: #Opening the file\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:                 #Going through each row in the file\n",
    "        if row['PdDistrict'] == '':\n",
    "            continue #Remove empty district\n",
    "        \n",
    "        date = row['Date'].split(\"/\")[-1]\n",
    "        if date == '2003':\n",
    "            if row['PdDistrict'] not in listOf2003Districts:\n",
    "                newDist = {} #Create new district because there aint any\n",
    "                newDist['Total'] = 0\n",
    "                newDist['P'] = 0\n",
    "                newDist['V'] = 0\n",
    "                newDist['District'] = row['PdDistrict']\n",
    "                listOf2003Districts[row['PdDistrict']] = newDist\n",
    "            listOf2003Districts[row['PdDistrict']]['Total'] = listOf2003Districts[row['PdDistrict']]['Total'] + 1\n",
    "            if row['Category'] == 'PROSTITUTION':\n",
    "                listOf2003Districts[row['PdDistrict']]['P'] = listOf2003Districts[row['PdDistrict']]['P'] + 1\n",
    "            elif row['Category'] == 'VEHICLE THEFT':\n",
    "                listOf2003Districts[row['PdDistrict']]['V'] = listOf2003Districts[row['PdDistrict']]['V'] + 1\n",
    "        elif date == '2015':\n",
    "            if row['PdDistrict'] not in listOf2015Districts:\n",
    "                newDist = {} #Create new district because there aint any\n",
    "                newDist['Total'] = 0\n",
    "                newDist['P'] = 0\n",
    "                newDist['V'] = 0\n",
    "                newDist['District'] = row['PdDistrict']\n",
    "                listOf2015Districts[row['PdDistrict']] = newDist\n",
    "            listOf2015Districts[row['PdDistrict']]['Total'] = listOf2015Districts[row['PdDistrict']]['Total'] + 1\n",
    "            if row['Category'] == 'PROSTITUTION':\n",
    "                listOf2015Districts[row['PdDistrict']]['P'] = listOf2015Districts[row['PdDistrict']]['P'] + 1\n",
    "            elif row['Category'] == 'VEHICLE THEFT':\n",
    "                listOf2015Districts[row['PdDistrict']]['V'] = listOf2015Districts[row['PdDistrict']]['V'] + 1\n",
    "    \n",
    "    \n",
    "print listOf2003Districts\n",
    "print listOf2015Districts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'P': 70, 'Total': 13622, 'District': 'CENTRAL', 'V': 1193}, {'P': 581, 'Total': 18975, 'District': 'NORTHERN', 'V': 1879}, {'P': 18, 'Total': 25692, 'District': 'SOUTHERN', 'V': 1426}, {'P': 2, 'Total': 8219, 'District': 'PARK', 'V': 1207}, {'P': 713, 'Total': 21163, 'District': 'MISSION', 'V': 2063}, {'P': 527, 'Total': 12737, 'District': 'TENDERLOIN', 'V': 371}, {'P': 15, 'Total': 7692, 'District': 'RICHMOND', 'V': 1081}, {'P': 10, 'Total': 11329, 'District': 'TARAVAL', 'V': 1665}, {'P': 5, 'Total': 14008, 'District': 'INGLESIDE', 'V': 2319}, {'P': 11, 'Total': 15739, 'District': 'BAYVIEW', 'V': 2121}]\n",
      "\n",
      "[{'P': 44, 'Total': 18565, 'District': 'CENTRAL', 'V': 552}, {'P': 42, 'Total': 20092, 'District': 'NORTHERN', 'V': 945}, {'P': 96, 'Total': 30095, 'District': 'SOUTHERN', 'V': 795}, {'P': 1, 'Total': 9341, 'District': 'PARK', 'V': 640}, {'P': 66, 'Total': 18542, 'District': 'MISSION', 'V': 1198}, {'P': 23, 'Total': 10735, 'District': 'TENDERLOIN', 'V': 113}, {'P': 9, 'Total': 9082, 'District': 'RICHMOND', 'V': 561}, {'P': 81, 'Total': 11966, 'District': 'TARAVAL', 'V': 789}, {'P': 5, 'Total': 13414, 'District': 'INGLESIDE', 'V': 1368}, {'P': 7, 'Total': 14711, 'District': 'BAYVIEW', 'V': 985}]\n"
     ]
    }
   ],
   "source": [
    "#sort\n",
    "list2003ForGraph = []\n",
    "list2015ForGraph = []\n",
    "\n",
    "for key, value in listOf2003Districts.iteritems():\n",
    "    list2003ForGraph.append(value)\n",
    "print list2003ForGraph\n",
    "print \"\"\n",
    "    \n",
    "for key, value in listOf2015Districts.iteritems():\n",
    "    list2015ForGraph.append(value)\n",
    "print list2015ForGraph\n",
    "\n",
    "with open('data2003.json', 'w') as outfile:\n",
    "    json.dump(list2003ForGraph, outfile)\n",
    "    \n",
    "with open('data2015.json', 'w') as outfile:\n",
    "    json.dump(list2015ForGraph, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Creating data for exercise 2:\n",
    "\n",
    "#First i make the input list of coordinates\n",
    "inputForClusters = []\n",
    "with open(\"SFPD.csv\", \"r\") as csvfile: #Opening the file\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        for row in reader: #Going through each row in the file\n",
    "            if row['Category'] == 'PROSTITUTION':\n",
    "                #Remove two corrdinates at 90.0, -120.5, which i assume is default for \"unknown coordinates\"\n",
    "                if float(row['X']) == -120.5:\n",
    "                    continue\n",
    "                    \n",
    "                coords = []\n",
    "                coords.append(float(row['X']))\n",
    "                coords.append(float(row['Y']) )  \n",
    "                inputForClusters.append(coords)\n",
    "\n",
    "\n",
    "#Defining KMeans class (Ref: DSFS p.226)\n",
    "class KMeans:\n",
    "    \"\"\"performs k-means clustering\"\"\"\n",
    "    def __init__(self, k):\n",
    "        self.k = k # number of clusters\n",
    "        self.means = None # means of clusters\n",
    "    def classify(self, input):\n",
    "        \"\"\"return the index of the cluster closest to the input\"\"\"\n",
    "        return min(range(self.k),\n",
    "                   key=lambda i: squared_distance(input, self.means[i]))\n",
    "    def train(self, inputs):\n",
    "        # choose k random points as the initial means\n",
    "        self.means = random.sample(inputs, self.k)\n",
    "        assignments = None\n",
    "        while True:\n",
    "            # Find new assignments\n",
    "            new_assignments = map(self.classify, inputs)\n",
    "            # If no assignments have changed, we're done.\n",
    "            if assignments == new_assignments:\n",
    "                return\n",
    "            # Otherwise keep the new assignments,\n",
    "            assignments = new_assignments\n",
    "            # And compute new means based on the new assignments\n",
    "            for i in range(self.k):\n",
    "                # find all the points assigned to cluster i\n",
    "                i_points = [p for p, a in zip(inputs, assignments) if a == i]\n",
    "                # make sure i_points is not empty so don't divide by 0\n",
    "                if i_points:\n",
    "                    self.means[i] = vector_mean(i_points)\n",
    "                    \n",
    "\n",
    "def squared_distance(p1, p2):\n",
    "    #Returns the squared distance between two points\n",
    "    return pow(p1[0] - p2[0], 2) + pow(p1[1] - p2[1], 2)\n",
    "        \n",
    "def vector_mean(points):\n",
    "    #Returns an average point(cluster) from a group of points\n",
    "    xsum = 0\n",
    "    ysum = 0\n",
    "    for i in points:\n",
    "        xsum = xsum + i[0]\n",
    "        ysum = ysum + i[1]\n",
    "    clusterCoords = []\n",
    "    clusterCoords.append(xsum/len(points))\n",
    "    clusterCoords.append(ysum/len(points))\n",
    "    return clusterCoords\n",
    "\n",
    "clusters = []\n",
    "for k in range(2, 7): #Creating the clusters with K = 2.... 10 on the prostitution data\n",
    "    cluster = KMeans(k)\n",
    "    cluster.train(inputForClusters)\n",
    "    clusters.append(cluster.means)\n",
    "\n",
    "dataForEx2 = {} #Creating the datastructure\n",
    "dataForEx2['kMeans'] = clusters\n",
    "dataForEx2['points'] = inputForClusters\n",
    "\n",
    "#Saving the datastructure to a json file\n",
    "\n",
    "with open('kmeansData.json', 'w') as outfile:\n",
    "    json.dump(dataForEx2, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-122.41924311718498, 37.760004216651865], [-122.41721258128312, 37.7873942622172]], [[-122.47811474903929, 37.73890648569838], [-122.41709742374623, 37.787424549877585], [-122.41582476469192, 37.761346056903236]], [[-122.40179500294863, 37.76495049257279], [-122.41634848878874, 37.76142307766684], [-122.47830161452609, 37.738985360292766], [-122.41735423515992, 37.78759808594881]], [[-122.41177998328493, 37.78497536427227], [-122.4126758146877, 37.7272752281478], [-122.41598334121794, 37.76173387931775], [-122.48002162922523, 37.73990346386408], [-122.41966402127976, 37.788600616797524]], [[-122.48691617278406, 37.75823743587129], [-122.46632498052561, 37.71881424708943], [-122.43024505010533, 37.79466698583476], [-122.41584224260983, 37.76142569868428], [-122.40445965523769, 37.785562650479555], [-122.41835342020613, 37.78737904400924]]]\n"
     ]
    }
   ],
   "source": [
    "print dataForEx2['kMeans']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
